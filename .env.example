# LLM Provider Configuration
USE_LOCAL_LLM=false
OPENAI_API_KEY=
OLLAMA_BASE_URL=http://localhost:11434

# Model Configuration (Fallback defaults - used if stage-specific not set)
AI_MODEL=gpt-4o-mini
AI_MODEL_REFINE=gpt-4o-mini

# Remote Model Configuration (when USE_LOCAL_LLM=false)
# Use these to assign different models for each workflow stage
REMOTE_MODEL_FILTERING=
REMOTE_MODEL_STRATEGY=
REMOTE_MODEL_PLANNING=
REMOTE_MODEL_ERROR_CORRECTION=
REMOTE_MODEL_REFINEMENT=

# Local Model Configuration (when USE_LOCAL_LLM=true)
# Use these to assign different Ollama models for each workflow stage
LOCAL_MODEL_FILTERING=
LOCAL_MODEL_STRATEGY=
LOCAL_MODEL_PLANNING=
LOCAL_MODEL_ERROR_CORRECTION=
LOCAL_MODEL_REFINEMENT=

# Planner Configuration
PLANNER_COMPLEXITY=minimal

# Database Configuration
DB_SERVER=
DB_NAME=
DB_USER=
DB_PASSWORD=
USE_TEST_DB=false

# Query Configuration
ERROR_CORRECTION_COUNT=3
REFINE_COUNT=2
TOP_MOST_RELEVANT_TABLES=8
EMBEDDING_MODEL=text-embedding-3-small

# Foreign Key Inference
INFER_FOREIGN_KEYS=false
FK_INFERENCE_CONFIDENCE_THRESHOLD=0.6
FK_INFERENCE_TOP_K=3

# Debug
ENABLE_DEBUG_FILES=true