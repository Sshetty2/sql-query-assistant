# LLM Provider Configuration
USE_LOCAL_LLM=false

# Remote Provider Selection (only used when USE_LOCAL_LLM=false)
# Options: "openai", "anthropic", or "auto"
# - "openai": Use OpenAI for all models
# - "anthropic": Use Anthropic for all models
# - "auto": Auto-detect provider from model name (allows mixing providers)
REMOTE_LLM_PROVIDER=openai

# API Keys
OPENAI_API_KEY=
ANTHROPIC_API_KEY=

# Ollama Configuration (only used when USE_LOCAL_LLM=true)
OLLAMA_BASE_URL=http://localhost:11434

# Remote Model Configuration (when USE_LOCAL_LLM=false)
# Use these to assign different models for each workflow stage
# When REMOTE_LLM_PROVIDER=auto, you can mix models from different providers
#
# Supported Model Aliases (auto mode):
# Anthropic: claude-sonnet-4-5, claude-haiku-4-5, claude-opus-4-1
# OpenAI: gpt-5, gpt-5-mini, gpt-5-nano, gpt-4o, gpt-4o-mini, o3, o3-mini, o1-mini
#
# Full model names also work (e.g., claude-3-5-sonnet-20241022, gpt-4o)
REMOTE_MODEL_FILTERING=
REMOTE_MODEL_STRATEGY=
REMOTE_MODEL_PLANNING=
REMOTE_MODEL_ERROR_CORRECTION=
REMOTE_MODEL_REFINEMENT=

# Local Model Configuration (when USE_LOCAL_LLM=true)
# Use these to assign different Ollama models for each workflow stage
LOCAL_MODEL_FILTERING=
LOCAL_MODEL_STRATEGY=
LOCAL_MODEL_PLANNING=
LOCAL_MODEL_ERROR_CORRECTION=
LOCAL_MODEL_REFINEMENT=

# Planner Configuration
PLANNER_COMPLEXITY=minimal

# Database Configuration
DB_SERVER=
DB_NAME=
DB_USER=
DB_PASSWORD=
USE_TEST_DB=false

# Query Configuration
ERROR_CORRECTION_COUNT=3
REFINE_COUNT=2
TOP_MOST_RELEVANT_TABLES=8
EMBEDDING_MODEL=text-embedding-3-small

# Foreign Key Inference
INFER_FOREIGN_KEYS=false
FK_INFERENCE_CONFIDENCE_THRESHOLD=0.6
FK_INFERENCE_TOP_K=3

# Debug
ENABLE_DEBUG_FILES=true