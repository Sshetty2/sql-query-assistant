# LLM Benchmark Results
**Date:** 2025-10-31 16:49:41

## Executive Summary

- **Total Runs:** 40
- **Successful Runs:** 31 (77.5%)
- **Models Tested:** 8
- **Queries Tested:** 5
- **Planner Complexity:** Minimal (all models)

## Overall Performance

| Model | Category | Avg Time (s) | Success Rate | Avg Quality Score | Avg Tokens | Est. Cost/Query |
|-------|----------|--------------|--------------|-------------------|------------|------------------|
| gpt-4o | remote | 150.54 | 100% | 66/100 | 308 | $0.003084 |
| gpt-4o-mini | remote | 34.44 | 60% | 39/100 | 300 | $0.000180 |
| gpt-5 | remote | 36.18 | 60% | 40/100 | 299 | $0.002994 |
| gpt-5-mini | remote | 32.09 | 80% | 53/100 | 295 | $0.000177 |
| llama3-8b | local | 142.77 | 80% | 52/100 | 287 | $0.000000 |
| llama3.1-8b | local | 24.86 | 100% | 66/100 | 312 | $0.000000 |
| qwen3-4b | local | 32.65 | 80% | 55/100 | 311 | $0.000000 |
| qwen3-8b | local | 38.54 | 60% | 34/100 | 266 | $0.000000 |

## Key Findings

- **Best Overall Quality:** gpt-4o (66/100)
- **Fastest:** llama3.1-8b (24.86s)
- **Best Value (Remote):** gpt-5-mini (53 quality / $0.000177)
- **Best Local Model:** llama3.1-8b (66/100)

## Query-by-Query Breakdown

### query_1_complex_user_activity

| Model | Success | Time (s) | Quality | Tokens | Cost |
|-------|---------|----------|---------|--------|------|
| gpt-4o |  | 14.67 | 80/100 | 288 | $0.002880 |
| gpt-4o-mini |  | 14.69 | 80/100 | 293 | $0.000176 |
| gpt-5 |  | 17.24 | 80/100 | 308 | $0.003080 |
| gpt-5-mini |  | 14.23 | 80/100 | 268 | $0.000161 |
| llama3.1-8b |  | 15.40 | 80/100 | 298 | $0.000000 |
| qwen3-4b |  | 15.20 | 80/100 | 287 | $0.000000 |
| llama3-8b |  | 17.77 | 63/100 | 196 | $0.000000 |
| qwen3-8b |  | 13.45 | 63/100 | 208 | $0.000000 |

### query_2_vulnerability_tracking

| Model | Success | Time (s) | Quality | Tokens | Cost |
|-------|---------|----------|---------|--------|------|
| llama3-8b |  | 27.95 | 61/100 | 363 | $0.000000 |
| qwen3-4b |  | 19.50 | 57/100 | 391 | $0.000000 |
| llama3.1-8b |  | 18.29 | 52/100 | 309 | $0.000000 |
| gpt-4o |  | 15.65 | 48/100 | 299 | $0.002990 |
| gpt-4o-mini |  | 16.29 | 48/100 | 297 | $0.000178 |
| gpt-5-mini |  | 18.26 | 48/100 | 351 | $0.000211 |
| gpt-5 | X | 64.31 | 0/100 | 363 | $0.003630 |
| qwen3-8b | X | 52.49 | 0/100 | 320 | $0.000000 |

### query_3_hardware_inventory

| Model | Success | Time (s) | Quality | Tokens | Cost |
|-------|---------|----------|---------|--------|------|
| gpt-4o |  | 14.51 | 68/100 | 289 | $0.002890 |
| gpt-4o-mini |  | 13.38 | 68/100 | 280 | $0.000168 |
| gpt-5-mini |  | 14.14 | 68/100 | 258 | $0.000155 |
| llama3-8b |  | 21.55 | 68/100 | 299 | $0.000000 |
| llama3.1-8b |  | 20.85 | 68/100 | 373 | $0.000000 |
| qwen3-4b |  | 14.02 | 68/100 | 283 | $0.000000 |
| qwen3-8b |  | 14.32 | 56/100 | 207 | $0.000000 |
| gpt-5 | X | 52.90 | 0/100 | 301 | $0.003010 |

### query_4_cross_domain_analysis

| Model | Success | Time (s) | Quality | Tokens | Cost |
|-------|---------|----------|---------|--------|------|
| gpt-4o |  | 39.82 | 83/100 | 385 | $0.003850 |
| gpt-5 |  | 31.09 | 83/100 | 291 | $0.002910 |
| llama3-8b |  | 15.42 | 68/100 | 292 | $0.000000 |
| llama3.1-8b |  | 25.49 | 68/100 | 282 | $0.000000 |
| qwen3-4b |  | 24.92 | 68/100 | 305 | $0.000000 |
| gpt-4o-mini | X | 48.09 | 0/100 | 309 | $0.000185 |
| gpt-5-mini | X | 65.42 | 0/100 | 308 | $0.000185 |
| qwen3-8b | X | 48.08 | 0/100 | 297 | $0.000000 |

### query_5_application_risk

| Model | Success | Time (s) | Quality | Tokens | Cost |
|-------|---------|----------|---------|--------|------|
| gpt-5-mini |  | 48.40 | 68/100 | 289 | $0.000173 |
| llama3.1-8b |  | 44.25 | 61/100 | 298 | $0.000000 |
| gpt-4o |  | 668.04 | 53/100 | 281 | $0.002810 |
| qwen3-8b |  | 64.36 | 53/100 | 297 | $0.000000 |
| gpt-5 |  | 15.34 | 36/100 | 234 | $0.002340 |
| gpt-4o-mini | X | 79.73 | 0/100 | 321 | $0.000193 |
| llama3-8b | X | 631.18 | 0/100 | 287 | $0.000000 |
| qwen3-4b | X | 89.61 | 0/100 | 289 | $0.000000 |

